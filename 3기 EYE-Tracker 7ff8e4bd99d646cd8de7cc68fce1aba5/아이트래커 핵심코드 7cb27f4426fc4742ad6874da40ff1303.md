# 아이트래커 핵심코드

아이트래커 사용 함수:

main(): darknet의 중심함수이며, 자신이 command창에서 입력한 명령을 바탕으로 darknet이 실행되게 됩니다.

run_dector(): test, train, valid, recall,map, calc_anchors, draw의 기능들을 제공하고 있습니다. 위의 기능들 중 하나를 선택하면, 단순 테스트기능, 그리기 기능 등을 진행하게 됩니다. 또한, 자신의 컴퓨터에 연결된 gpu의 정보를 받아 gpu를 좀 더 effective하게 사용한다. main()에서 넘어가는 함수이며, demo로 넘어간다.

demo(): 명령문에서 지정한 가중치 파일을 불러오며, 또한, 실시간으로 eye tracker의 gaze point를 불러와 객체들을 인식할 준비를 한다.

get_qr code_touch_gazepoint(): 인풋 이미지와 gazepoint의 x와 y좌표들의 이 함수에 들어갑니다. 아래의 함수들을 이용하여, ar_marker들을 찾는다. 발견한 마커들은 고유한 아이디가 있기 때문에 그것을 정리하며, 실험참가자 몇 번 째의 모니터를 주시하고 있는지 알려준다. 아래의 함수를 통해 gaze point를 원하는 좌표로 변형시켜 준다.

aruco::detectMarkers(): 인풋이미지와 새롭게 생성한 딕셔너리와 모서리, 고유이름들을 aruco 고유의 함수에 넣어준다. 이 함수는 인풋이미지에 있는 ar_marker들을 발견하여, 각각의 모서리 좌표들과 고유이름들을 corners와 ids에 vector의 형태로 저장하게 된다. 부착한 ar_marker들을 인식하여, marker의 좌표, 개수를 인식한다.

getPerspectiveTransform(): 발견한 ar_marker들의 꼭짓점들을 기준으로 Perspective한 좌표으로 변형시킨다. 최소한 4개의 좌표가 존재해야 정확한 perspective한 모델을 얻을 수 있다.
warpPerspective(): 위에서 변형된 좌표들로 변형시켜야할 인풋 이미지를 Perspective하게 변형시켜 아웃풋 이미지로 만들어 준다.

draw_detections_cv_v3: 발견된 객체들의 이름들과 좌표 등을 받는다. 그 후,opencv과 함께 각 객체들에 bounding 박스들을 그린다. 만약, 객체들 사이에 side_mirror가 있으면, 발견된 ar_marker 고유의 번호에 따라 left,right를 결정시켜 객체의 이름을 바꾼다.

[src.zip](%E1%84%8B%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%90%E1%85%B3%E1%84%85%E1%85%A2%E1%84%8F%E1%85%A5%20%E1%84%92%E1%85%A2%E1%86%A8%E1%84%89%E1%85%B5%E1%86%B7%E1%84%8F%E1%85%A9%E1%84%83%E1%85%B3%207cb27f4426fc4742ad6874da40ff1303/src.zip)